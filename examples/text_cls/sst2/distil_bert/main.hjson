{
    "root": {
        "_name": "pretrained",
        "_link": {
            "config.meta_data": ['task.imodel.postprocessor.config.meta'],
            "config.pretrained_model_path": ['task.imodel.model.config.pretrained_model_path'],
        },
        "_search": {},
        "config": {
            "save_dir": "distil_bert/data/output",  # must provide
            "data_path": "distil_bert/data/output/processed_data.pkl",  # must provide
            "meta_data": "distil_bert/data/output/meta.pkl",  # must provide
            "config.save_dir": ['task.imodel.postprocessor.config.save_root_path'],
            "pretrained_model_path": "./pretrained_model/finetuned_distil_bert_id"
        },
        "task": {
            "manager": {
                "_base": "lightning",
                "config":{
                    "callbacks": [ //remove checkpoint callback
                    ],
                    "enable_checkpointing": false,
                    "max_epochs": 2,
                    "accelerator": 'gpu', //or cpu
                    "devices": 1,
                    "precision": 32,
                    "strategy": "ddp", // if you want use multi-gpus to predict, please use dp now, this is because ddp will prepare data multi times on one node, and the gather process is not implement
                }
            },
            "imodel": {
                "_base": "basic@txt_cls",
                "model": {
                    "_base": "basic@txt_cls#pretrained_transformers",
                    "embedding": {
                        "_base": "pretrained_transformers",
                        "module": {
                            "config": {
                                "pretrained_model_path": "*@*",
                            },
                            "_base": "distil_bert",
                        },
                    },
                    "config": {
                        "embedding_dim": 768,
                        "label_num": 2,
                        /*"pretrained_model_path": "./local_data/pretrained_model/roberta_base",*/
                        "pretrained_model_path": "./distil_bert/data/model",
                        "dropout": 0.3,
                    },
                },
                "optimizer": {
                    "config": {
                        "lr": 2e-5,
                    },
                },
                "postprocessor": {
                    "config": {
                        "meta": '*@*'
                    }
                },
            },
            "datamodule": {
                "_base": "basic@txt_cls",
                "config":{
                   "train_batch_size": 32,
                   "predict_batch_size": 32, //predict„ÄÅtest batch_size is equals to valid_batch_size
                }
            },
        },
    },
    "_focus": {
        "root._name": "task."
    },
}
