{
    "root": {
        "_name": "bert"
        "_search": {},
        "config": {
            "save_dir": "./bert/output",  # must provide
            "data_path": "./bert/output/processed_data.pkl",  # must provide
            "meta_data": "./bert/output/meta.pkl",  # must provide
            "pretrained_model_path": './model/',  # must provide
            "entity_label_num": 2,
            "relation_label_num": 2, # each group
        },
        "_link": {
            "config.meta_data": ['task.imodel.postprocessor.config.meta'],
            "config.entity_label_num": ['task.imodel.model.config.entity_label_num'],
            "config.relation_label_num": ['task.imodel.model.config.relation_label_num'],
            "config.pretrained_model_path": ['task.imodel.model.config.pretrained_model_path'],
            "config.save_dir": ['task.imodel.postprocessor.config.save_root_path'],
        },
        "task": {
            "manager": {
                "_base": "lightning",
                "config":{
                    "callbacks": [ # remove checkpoint callback
                    ],
                    "enable_checkpointing": false,
                    "profiler": null,
                    "max_epochs": 50,
                    "accelerator": 'gpu', # or cpu
                    "devices": 1,
                    "precision": 32,
                    "strategy": "ddp", # if you want use multi-gpus to predict, please use dp now, this is because ddp will prepare data multi times on one node, and the gather process is not implement
                    "detect_anomaly": false,
                }
            },
            "imodel": {
                "_base": "basic@span_relation",
                "model": {
                    "_base": "basic@span_relation#pretrained_transformer",
                    "config": {
                        "embedding_dim": 768,
                        "pretrained_model_path": "*@*",
                        "dropout": 0.3,
                        "entity_label_num": "*@*",
                        "relation_label_num": "*@*", # each group
                        "multi_matrix": 2, # 2 for head pair and tail pair
                    },
                    "embedding": {
                        "_base": "pretrained_transformers",
                        "module": {
                            "_base": "bert",
                        },
                    },
                },
                "scheduler": {
                    "_base": "linear_warmup",
                },
                "optimizer": {
                    "_base": "adamw@bias_nodecay",
                    "config": {
                        "lr": 3e-5,
                        "optimizer_special_groups": {
                            # "order": ['decoder', 'bias'], # the group order, if the para is in decoder & is in bias, set to decoder
                            "order": ['bias', 'decoder'], 
                            "bias": {
                                "config": {
                                    "weight_decay": 0
                                },
                                "pattern": ["bias",  "LayerNorm\\.bias", "LayerNorm\\.weight"]
                            },
                            "decoder": {
                                "config": {
                                    "lr": 1e-3
                                },
                                "pattern": ["decoder"]
                            },
                        }
                    },
                },
                "loss": {
                    "loss@entity":{
                        "config": {
                            "label_smoothing": 0.0, # torch>=1.10
                        }
                    },
                    "loss@relation":{
                        "config": {
                            "label_smoothing": 0.0, # torch>=1.10
                        }
                    }
                },
                "postprocessor": {
                    "config": {
                        "meta": '*@*'
                        "start_save_step": 0,  # -1 means the last
                        "start_save_epoch": 0,
                        "save_root_path": "./bert/"
                    }
                },
            },
            "datamodule": {
                "_base": "basic@span_relation",
                "config":{
                   "train_batch_size": 16,
                   "predict_batch_size": 32, # predict„ÄÅtest batch_size is equals to valid_batch_size
                }
            },
        },
    },
    "_focus": {
        "root._name": "task."
    },
}
