{
    "@fit": {
        "specific": {},
        "log_dir": "./logs",
        "processed_data_dir": "./data/processed_data",
        "@trainer@lightning": {
            "max_epochs": 50,
            "devices": "auto",
            "strategy": "auto",
            "accelerator": "auto",
            "precision": "16",
            "@callback@lr_monitor": {
                "logging_interval": "step"
            },
            "@callback@checkpoint": {
                "monitor": "val_rel_f1",
                "mode": "max",
                "save_top_k": 1
            }
        },
        "@datamodule@default": {
            "train_batch_size": 24,
            "predict_batch_size": 64,
            "num_workers": -1,
            "pin_memory": true,
            "shuffle": true,
            "@dataset@default": {
                "repeat_for_valid": false,
                "key_type_pairs": {
                    "input_ids": "int",
                    "entity_label_ids": "long",
                    "relation_label_ids": "long",
                    "gather_index": "long",
                    "type_ids": "long",
                    "special_tokens_mask": "int"
                }
            },
            "@data_collate@default": {
                "gen_mask": {
                    "input_ids": "attention_mask"
                },
                "key_padding_pairs": {
                    "input_ids": 0,
                    "attention_mask": 0,
                    "special_tokens_mask": 0,
                    "type_ids": 0
                },
                "key_padding_pairs_2d": {
                    "entity_label_ids": -100
                },
                "key_padding_pairs_3d": {
                    "relation_label_ids": -100
                }
            }
        },
        "@imodel@default": {
            "@model@basic": {
                "@initmethod@default": {},
                "@embedding@bert_like": {
                    "from_pretrain": true,
                    "pretrained_model_path": "./../sequence_labeling/data/bert/",
                    "embedding_dim": 768,
                    "dropout": 0.1
                },
                "@encoder@identity": {},
                "@decoder@multi_decoder": {
                    "@decoder@biaffine#entity": {
                        "input_size": "@lambda @$$$.@embedding.embedding_dim",
                        "output_size": 20,
                        "dropout": 0.1,
                        "bias": true,
                        "active": "none",
                        "output_map": {
                            "logits": "entity_logits"
                        }
                    },
                    "@decoder@biaffine#relation": {
                        "input_size": "@lambda @$$$.@embedding.embedding_dim",
                        "output_size": 25,
                        "multi_matrix": 2, // 2 for head pair and tail pair
                        "dropout": 0.1,
                        "active": "none",
                        "bias": true,
                        "output_map": {
                            "logits": "relation_logits"
                        }
                    }
                }
            },
            "@scheduler@cosine_restart": {
                "num_warmup_steps": 0.01,
                "interval": "epoch",
                "first_restart_step": 2
            },
            "@loss@multi_loss": {
                "loss_collect": "sum",
                "@loss@cross_entropy#entity": {
                    "pred_truth_pair": {
                        "entity_logits": "entity_label_ids"
                    },
                    "weight": "@$$$.@model.@decoder.#entity.output_size @lambda x: [0.5]+[20]*(x-1)",
                    "label_smoothing": 0.0001,
                    "ignore_index": -100
                },
                "@loss@cross_entropy#relation": {
                    "pred_truth_pair": {
                        "relation_logits": "relation_label_ids"
                    },
                    "weight": "@$$$.@model.@decoder.#relation.output_size @lambda x: [0.5]+[20]*(x-1)",
                    "ignore_index": -100,
                    "label_smoothing": 0.0001
                }
            },
            "@optimizer@adamw": {
                "lr": 3e-5,
                "eps": 1e-05,
                "optimizer_special_groups": {
                    "order": [
                        "decoder",
                        "bias"
                    ], // the group order, if the para is in decoder & is in bias, set to decoder
                    "bias": {
                        "config": {
                            "weight_decay": 0
                        },
                        "pattern": [
                            "bias",
                            "LayerNorm\\.bias",
                            "LayerNorm\\.weight"
                        ]
                    },
                    "decoder": {
                        "config": {
                            "lr": 5e-4
                        },
                        "pattern": [
                            "decoder"
                        ]
                    }
                }
            },
            "@postprocessor@span_relation": {
                "entity_label_vocab": "label_vocab#entity.json",
                "relation_label_vocab": "label_vocab#relation.json",
                "tokenizer_path": "./../sequence_labeling/data/bert/tokenizer.json",
                "start_save_epoch": 1,
                "sym": false
            }
        }
    }
}
