{
    "processor": {
        "_name": "basic@translation",
        "config": {
            "encoder_tokenizer_config_path": "./data/tokenizer/de_tokenizer.json", // the tokenizer config path (the tokenizer.json path)
            "decoder_tokenizer_config_path": "./data/tokenizer/en_tokenizer.json", // the tokenizer config path (the tokenizer.json path)
            "data_dir": "./transformer/data/output/",  // save load data base dir
            "encoder_embedding_size": 20,
            "decoder_embedding_size": 20,
            "encoder_embedding_file": null,
            "decoder_embedding_file": null,
            "feed_order": [
                "load",
                "translation_loader",
                "encoder_tokenizer",
                "decoder_tokenizer",
                "encoder_token_embedding",
                "decoder_token_embedding",
                "save"
            ],
        },
        "_link": {
            "config.encoder_tokenizer_config_path": ["subprocessor@encoder_tokenizer.config.train.config_path", 'subprocessor@encoder_token_embedding.config.train.tokenizer'],
            "config.decoder_tokenizer_config_path": ["subprocessor@decoder_tokenizer.config.train.config_path", 'subprocessor@decoder_token_embedding.config.train.tokenizer'],
            "config.data_dir": ["subprocessor@load.config.base_dir", "subprocessor@save.config.base_dir"],
            "config.encoder_embedding_file": "subprocessor@encoder_token_embedding.config.train.embedding_file",
            "config.decoder_embedding_file": "subprocessor@decoder_token_embedding.config.train.embedding_file",
            "config.encoder_embedding_size": "subprocessor@encoder_token_embedding.config.train.embedding_size",
            "config.decoder_embedding_size": "subprocessor@decoder_token_embedding.config.train.embedding_size",
        },
        "subprocessor@load": {
            "_base": "load",
            "config":{
                "base_dir": "*@*",
                "predict":{
                    "meta": "./meta.pkl",
                },
                "online": [
                    "predict", //base predict
                    {   // special config, update predict, is this case, the config is null, means use all config from "predict", when this is empty dict, you can only set the value to a str "predict", they will get the same result
                    }
                ]
            }
        },
        "subprocessor@save": {
            "_base": "save",
            "config":{
                "base_dir": "*@*",
                "train":{
                    "processed": "processed_data.pkl", // all data
                    "meta": {
                        "meta.pkl": ["encoder_tokenizer", 'encoder_token_embedding', "decoder_tokenizer", "decoder_token_embedding"], //only for next time use
                    }
                },
                "predict": {
                    "processed": "processed_data.pkl",
                }
            }
        },
        "subprocessor@translation_loader":{
            "_name": "basic_data_loader@translation",
            "config": {
                "train":{
                    "data_set": {                   // for different stage, this processor will process different part of data
                        "train": ['train', 'valid', 'test', 'predict'],
                        "predict": ['predict'],
                        "online": ['online']
                    },
                    "input_map": {   // without necessery don't change this
                        "encoder": "encoder",
                        "uuid": "uuid",
                        "decoder": "decoder",
                    },
                    "output_map": {
                        "encoder": "encoder",
                        "uuid": "uuid",
                        "decoder": "decoder",
                    },
                },
                "predict": "train",
                "online": "train",
            }
        },
        "subprocessor@encoder_tokenizer":{
            "_base": "fast_tokenizer",
            "config": {
                "train": {
                    "config_path": "*@*",
                    "data_type": "single", // single or pair, if not provide, will calc by len(process_data)
                    "process_data": { "is_pretokenized": false},
                    "post_processor": "default",
                    "input_map": {   // without necessery don't change this
                        "sentence": "encoder",
                    },
                    "output_map": { // this is the default value, you can provide other name
                        "tokens": "encoder_tokens",
                        "ids": "encoder_input_ids",
                        "attention_mask": "encoder_attention_mask",
                        "type_ids": "encoder_type_ids",
                        "special_tokens_mask": "encoder_special_tokens_mask",
                        "offsets": "encoder_offsets",
                        "word_ids": "encoder_word_ids",
                        "overflowing": "encoder_overflowing",
                        "sequence_ids": "encoder_sequence_ids",
                    }, // the tokenizer output(the key) map to the value
                    "deliver": "encoder_tokenizer",
                },
                "predict": "train",
                "online": "train"
            }
        },
        "subprocessor@decoder_tokenizer":{
            "_base": "fast_tokenizer",
            "config": {
                "train": {
                    "config_path": "*@*",
                    "data_type": "single", // single or pair, if not provide, will calc by len(process_data)
                    "process_data": { "is_pretokenized": false},
                    "post_processor": "default",
                    "input_map": {   // without necessery don't change this
                        "sentence": "decoder",
                    },
                    "output_map": { // this is the default value, you can provide other name
                        "tokens": "decoder_tokens",
                        "ids": "decoder_input_ids",
                        "attention_mask": "decoder_attention_mask",
                        "type_ids": "decoder_type_ids",
                        "special_tokens_mask": "decoder_special_tokens_mask",
                        "offsets": "decoder_offsets",
                        "word_ids": "decoder_word_ids",
                        "overflowing": "decoder_overflowing",
                        "sequence_ids": "decoder_sequence_ids",
                    }, // the tokenizer output(the key) map to the value
                    "deliver": "decoder_tokenizer",
                },
                "predict": "train",
                "online": "train"
            }
        },
        "subprocessor@encoder_token_embedding": {
            "_base": "token_embedding",
            "config":{
                "train": { // only train stage using
                    "embedding_file": "*@*",
                    "tokenizer": "*@*",
                    "deliver": "encoder_token_embedding",
                    "embedding_size": "*@*",
                }
            }
        },
        "subprocessor@decoder_token_embedding": {
            "_base": "token_embedding",
            "config":{
                "train": { // only train stage using
                    "embedding_file": "*@*",
                    "tokenizer": "*@*",
                    "deliver": "decoder_token_embedding",
                    "embedding_size": "*@*",
                }
            }
        },
    }
}
