{
    "process": [
        {
            "process_name": "space_tokenizer"
            "config": {
                "from": ["origin"],
                "to": ["origin_tokens"],
                "save_tokens": "./data/test/tokens.txt",
                "save_method": "new" // new or append 比如输入和输出都有时采用append, 只有输入采用new
            }
        },
        {
            "process_name": "label_to_id",
            "config": {
                "from": ["label"],
                "to": ["label_id"],
                "save_label_id": "./data/test/label_id_map.pkl"
            }
        },
        {
            "process_name": "get_embedding",
            "config": {
                "tokens": "",
                "embedding_file": "./data/resource/embedding.txt"
                "restruct_embedding_id": true,
                "save_embedding": "./data/test/embedding.txt",
                "token_id_map": "./data/test/token_id_map.pkl"
            }
        },

        {
            "process_name": "token_to_id",
            "config": {
                "token_id_map": "",
                "token": "origin_tokens",
                "ids": "origin_token_ids",
            }
        },
    ],

    "save_path": "./data/test/data.pkl",
    "_link": {
        "process.0.config.save_tokens":"process.2.config.tokens",
        "process.2.config.token_id_map":"process.-1.config.token_id_map",
    }
}
