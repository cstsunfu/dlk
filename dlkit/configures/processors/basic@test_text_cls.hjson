{
    "_name": "basic@test_text_cls",
    "config": {
        "feed_order": ["load", "tokenizer", "token_gather", "label_to_id", "save"]
    },
    "subprocessor@load": {
        "_base": "load",
        "config":{
            "base_dir": "."
            "predict":{
                "label_vocab": "./label_vocab.pkl",
            },
            "online": [
                "predict", //base predict
                {   // special config, update predict, is this case, the config is null, means use all config from "predict"
                }
            ]
        }
    },
    "subprocessor@save": {
        "_name": "save",
        "config":{
            "base_dir": "."
            "train":{
                "data.train": "./train.pkl",
                "data.dev": "./dev.pkl",
                "label_vocab": "./label_vocab.pkl",
            },
            "predict": {
                "data.predict": "./predict.pkl"
            }
        }
    },
    "subprocessor@tokenizer":{
        "_base": "wordpiece_tokenizer",
        "config": { 
            "train": { 
                "config_path": "*@*",
                "data_type": "single", // single or pair, if not provide, will calc by len(process_data)
                "process_data": [
                    ["sentence", { "is_pretokenized": false}], 
                ],
                "post_processor": "bert"
            },
            "predict": "train",
            "online": "train"
        }
    },
    "subprocessor@token_gather":{
        "_base": "token_gather",
        "config": {
            "train": { // only train stage using
                "data_set": {      // for different stage, this processor will process different part of data
                    "train": ["train", "dev"]
                },
                "gather_columns": ["label"], //List of columns. Every cell must be sigle token or list of tokens or set of tokens
                "deliver": "label_vocab", // output Vocabulary object (the Vocabulary of labels) name. 
            }
        }
    },
    "subprocessor@label_to_id":{
        "_base": "token2id",
        "config": {
            "train":{ //train、predict、online stage config,  using '&' split all stages
                "data_pair": {
                    "label": "label_id"
                },
                "data_set": {                   // for different stage, this processor will process different part of data
                    "train": ['train', 'dev'],
                    "predict": ['predict'],
                    "online": ['online']
                },
                "vocab": "label_vocab", // usually provided by the "token_gather" module
            }, //3
            "predict": "train",
            "online": "train",
        }
    }
}
