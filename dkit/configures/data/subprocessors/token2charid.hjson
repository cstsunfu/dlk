{
    "_name": "token2charid",
    "config": {
        "train":{
            "data_pair": {
                "sentence & offsets": "char_ids"
            },
            "data_set": {                   // for different stage, this processor will process different part of data
                "train": ['train', 'valid', 'test', 'predict'],
                "predict": ['predict'],
                "online": ['online']
            },
            "vocab": "char_vocab", // usually provided by the "token_gather" module
            "max_token_len": 20, // the max length of token, then the output will be max_token_len x token_num (put max_token_len in previor is for padding on token_num)
        },
        "predict": "train",
        "online": "train",
    }
}
